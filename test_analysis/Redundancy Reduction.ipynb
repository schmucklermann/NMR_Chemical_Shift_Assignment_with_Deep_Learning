{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7b1ee554",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ace5d89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ea103ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_hn = \"./data/bmrb_IDs_monomer_pH68.txt\"\n",
    "feature_file = \"./data/bmrb_detail_monomer_pH68.txt\"\n",
    "fasta_file = \"./data/bmrb_monomer_pH68.fasta\"\n",
    "\n",
    "cluster_mmseqs2 = \"./data/clusterRes_cluster.tsv\" #seq_id = 30%\n",
    "cluster_rep_mmseqs2 = \"./data/clusterRes_rep_seq.fasta\" #seq_id = 30%\n",
    "\n",
    "graph_part = \"./data/graphpart/graphpart_assignments.csv\" #seq_id = 30% test=20% val=10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "363f6296",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_representatives(cluster_rep):\n",
    "    cl_repr = []\n",
    "\n",
    "    with open(cluster_rep, 'r') as fasta:\n",
    "            lines = fasta.read().split(\"\\n\")\n",
    "            for line in lines:\n",
    "                if line.startswith(\">\"):\n",
    "                    cl_repr.append(int(line[1:]))\n",
    "\n",
    "    print(\"Cluster Representative Sequences: \"+str(len(cl_repr)))\n",
    "    \n",
    "    return cl_repr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "da3ef092",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_fasta(fasta):\n",
    "    fasta_dct = {}\n",
    "\n",
    "    with open(fasta, 'r') as f:\n",
    "            lines = f.read().split(\"\\n\")\n",
    "            for i,line in enumerate(lines):\n",
    "                if line.startswith(\">\"):\n",
    "                    fasta_dct[int(line[1:])] = lines[i+1]\n",
    "\n",
    "    return fasta_dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0ed5c874",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_df(df, ids):\n",
    "    \n",
    "    df = df.drop(df[~df['BRMB_ID'].isin(ids)].index)\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a10fd7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_members(file):\n",
    "    \n",
    "    df_clusters = pd.read_csv(file, sep=\"\\t\", header = None)\n",
    "\n",
    "    #df for cluster members\n",
    "    cluster_members = {}\n",
    "\n",
    "    for index, row in df_clusters.iterrows():\n",
    "        rep = row[0]\n",
    "        memb = row[1]\n",
    "\n",
    "        if rep not in cluster_members:\n",
    "            cluster_members[rep] = [memb]\n",
    "        else:\n",
    "            l = cluster_members[rep]\n",
    "            l.append(memb)\n",
    "            cluster_members[rep] = l\n",
    "            \n",
    "    return cluster_members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "882b0d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Representative Sequences: 3392\n"
     ]
    }
   ],
   "source": [
    "cl_repr = get_cluster_representatives(cluster_rep_mmseqs2)\n",
    "\n",
    "df_features = pd.read_csv(feature_file, sep=\"\\t\")\n",
    "df_features_mmseqs2 = filter_df(df_features, cl_repr)\n",
    "#df_features_mmseqs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d4de4b36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BRMB_ID</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>Sequence_ID</th>\n",
       "      <th>Ion</th>\n",
       "      <th>pH</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Experiment</th>\n",
       "      <th>Cluster_Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30079</td>\n",
       "      <td>MTPIEYIDRALALVVDRLARYPGYEVLLSAEKQLQYIRSVLLDRSL...</td>\n",
       "      <td>A</td>\n",
       "      <td>0.10</td>\n",
       "      <td>6.0</td>\n",
       "      <td>298.0</td>\n",
       "      <td>SOLUTION</td>\n",
       "      <td>[30079]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11218</td>\n",
       "      <td>GSSGSSGPARPFRVSNHDRSSRRGVMASSLQELISKTLDALVIATG...</td>\n",
       "      <td>A</td>\n",
       "      <td>0.12</td>\n",
       "      <td>7.0</td>\n",
       "      <td>298.0</td>\n",
       "      <td>solution</td>\n",
       "      <td>[11218, 4574]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7248</td>\n",
       "      <td>RKKKDIRDYNDADMARLLEQWEKDDDIEEGDLPEHKRPSAPIDFSK...</td>\n",
       "      <td>.</td>\n",
       "      <td>0.10</td>\n",
       "      <td>7.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[7248, 16213]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17664</td>\n",
       "      <td>GPLGSSCKTSWADRVREAAAQRR</td>\n",
       "      <td>.</td>\n",
       "      <td>0.05</td>\n",
       "      <td>6.2</td>\n",
       "      <td>303.0</td>\n",
       "      <td>solution</td>\n",
       "      <td>[17664]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5471</td>\n",
       "      <td>MAQTITQSRLRIDANFKRFVDEEVLPGTGLDAAAFWRNFDEIVHDL...</td>\n",
       "      <td>.</td>\n",
       "      <td>0.10</td>\n",
       "      <td>7.1</td>\n",
       "      <td>310.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[5471]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3387</th>\n",
       "      <td>50218</td>\n",
       "      <td>RLRATVSRPVSHQRMGTPMVENDSGYKLGQRVRHAKFGEGTIVNME...</td>\n",
       "      <td>.</td>\n",
       "      <td>0.07</td>\n",
       "      <td>6.5</td>\n",
       "      <td>310.0</td>\n",
       "      <td>solution</td>\n",
       "      <td>[50218]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3388</th>\n",
       "      <td>16471</td>\n",
       "      <td>KGIAEKTVLELMNPEAQLPQVYPFAADLYQKELATLQQQSPEHSLT...</td>\n",
       "      <td>.</td>\n",
       "      <td>0.15</td>\n",
       "      <td>7.5</td>\n",
       "      <td>303.0</td>\n",
       "      <td>solution</td>\n",
       "      <td>[16471]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3389</th>\n",
       "      <td>50362</td>\n",
       "      <td>GAMGPKSKEELLREKLSEDQKTHLDWLKEALGNDGEFDKFLGYDES...</td>\n",
       "      <td>.</td>\n",
       "      <td>0.08</td>\n",
       "      <td>6.8</td>\n",
       "      <td>298.0</td>\n",
       "      <td>solution</td>\n",
       "      <td>[50362, 50360, 50328, 34344]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3390</th>\n",
       "      <td>27396</td>\n",
       "      <td>SEAVIKVISSACKTYCGKTSPSKKEIGAMLSLLQKEGLLMSPSDLY...</td>\n",
       "      <td>A</td>\n",
       "      <td>0.10</td>\n",
       "      <td>6.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>solution</td>\n",
       "      <td>[27396, 30404]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3391</th>\n",
       "      <td>16926</td>\n",
       "      <td>GSHMSTLERVVYRPDINQGNYLTANDVSKIRVGMTQQQVAYALGTP...</td>\n",
       "      <td>A</td>\n",
       "      <td>0.02</td>\n",
       "      <td>6.6</td>\n",
       "      <td>298.0</td>\n",
       "      <td>NMR, 20 STRUCTURES</td>\n",
       "      <td>[16926, 16424]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3392 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      BRMB_ID                                           Sequence Sequence_ID   \n",
       "0       30079  MTPIEYIDRALALVVDRLARYPGYEVLLSAEKQLQYIRSVLLDRSL...           A  \\\n",
       "1       11218  GSSGSSGPARPFRVSNHDRSSRRGVMASSLQELISKTLDALVIATG...           A   \n",
       "2        7248  RKKKDIRDYNDADMARLLEQWEKDDDIEEGDLPEHKRPSAPIDFSK...           .   \n",
       "3       17664                            GPLGSSCKTSWADRVREAAAQRR           .   \n",
       "4        5471  MAQTITQSRLRIDANFKRFVDEEVLPGTGLDAAAFWRNFDEIVHDL...           .   \n",
       "...       ...                                                ...         ...   \n",
       "3387    50218  RLRATVSRPVSHQRMGTPMVENDSGYKLGQRVRHAKFGEGTIVNME...           .   \n",
       "3388    16471  KGIAEKTVLELMNPEAQLPQVYPFAADLYQKELATLQQQSPEHSLT...           .   \n",
       "3389    50362  GAMGPKSKEELLREKLSEDQKTHLDWLKEALGNDGEFDKFLGYDES...           .   \n",
       "3390    27396  SEAVIKVISSACKTYCGKTSPSKKEIGAMLSLLQKEGLLMSPSDLY...           A   \n",
       "3391    16926  GSHMSTLERVVYRPDINQGNYLTANDVSKIRVGMTQQQVAYALGTP...           A   \n",
       "\n",
       "       Ion   pH  Temperature          Experiment                  Cluster_Size  \n",
       "0     0.10  6.0        298.0            SOLUTION                       [30079]  \n",
       "1     0.12  7.0        298.0            solution                 [11218, 4574]  \n",
       "2     0.10  7.0        303.0                 NaN                 [7248, 16213]  \n",
       "3     0.05  6.2        303.0            solution                       [17664]  \n",
       "4     0.10  7.1        310.0                 NaN                        [5471]  \n",
       "...    ...  ...          ...                 ...                           ...  \n",
       "3387  0.07  6.5        310.0            solution                       [50218]  \n",
       "3388  0.15  7.5        303.0            solution                       [16471]  \n",
       "3389  0.08  6.8        298.0            solution  [50362, 50360, 50328, 34344]  \n",
       "3390  0.10  6.0        305.0            solution                [27396, 30404]  \n",
       "3391  0.02  6.6        298.0  NMR, 20 STRUCTURES                [16926, 16424]  \n",
       "\n",
       "[3392 rows x 8 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fasta_dct = read_fasta(fasta_file)\n",
    "\n",
    "cluster_members = get_cluster_members(cluster_mmseqs2) \n",
    "\n",
    "\n",
    "#add size of clusters to data frame\n",
    "cl_size = [cluster_members[row[0]] for index, row in df_features_mmseqs2.iterrows()]\n",
    "df_features_mmseqs2['Cluster_Size'] = cl_size\n",
    "df_features_mmseqs2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8184d822",
   "metadata": {},
   "source": [
    "# Train-Validation-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "957b7892",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_clusters(df, n):\n",
    "    \n",
    "    counter = 0\n",
    "    index_list = []\n",
    "    ids = []\n",
    "        \n",
    "    for index, row in df.iterrows():\n",
    "        s = len(row[7])\n",
    "        \n",
    "        if counter == n:\n",
    "            break\n",
    "        else:\n",
    "            counter += s\n",
    "            if counter > n:\n",
    "                counter -= s\n",
    "                continue\n",
    "            else:\n",
    "                index_list.append(index)\n",
    "                ids.append(row[7])\n",
    "                \n",
    "    \n",
    "    df = df.drop(index_list)\n",
    "    \n",
    "    return df, ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "98fda978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_split(df, test, valid):\n",
    "    \n",
    "    # randomly shuffle the dataframe\n",
    "    df = df.reindex(np.random.permutation(df.index)) \n",
    "    \n",
    "    df_rest, valid = collect_clusters(df, valid)    \n",
    "    df_rest, test = collect_clusters(df_rest, test)  \n",
    "    \n",
    "    train = df_rest['Cluster_Size'].values\n",
    "    \n",
    "    \n",
    "\n",
    "    \"\"\" # how many records is one-fifth of the entire dataframe\n",
    "    #fifth = int(len(df) / 5)\n",
    "\n",
    "    # Test set (the top fifth from the entire dataframe)\n",
    "    test_df = df[:test]#[:fifth]\n",
    "\n",
    "    df_rest = df[test:]#[fifth:]\n",
    "    #tenth = int(len(df_rest) / 10)\n",
    "\n",
    "    # Testing set (top half of the remainder two third of the dataframe)\n",
    "    valid_df = df_rest[:valid]#[:tenth]\n",
    "\n",
    "    # Validation set (bottom one third)\n",
    "    train_df = df_rest[valid:]#[tenth:]\"\"\"\n",
    "\n",
    "    return train,valid,test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "985b34b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_fasta(df, outfile):\n",
    "\n",
    "    file = open(outfile, 'w')\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        id_ = row['BRMB_ID']\n",
    "        seq = row['Sequence']\n",
    "        file.write(f'>{id_}\\n{seq}\\n')\n",
    "\n",
    "   \n",
    "    file.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "070fee5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6609\n",
      "250\n",
      "250\n"
     ]
    }
   ],
   "source": [
    "train,valid,test = train_val_test_split(df_features_mmseqs2, test=250, valid=250)\n",
    "\n",
    "\n",
    "df_train = df_features[df_features['BRMB_ID'].isin(sum(train, []))]\n",
    "df_test = df_features[df_features['BRMB_ID'].isin(sum(test, []))]\n",
    "df_valid = df_features[df_features['BRMB_ID'].isin(sum(valid, []))]\n",
    "\n",
    "write_fasta(df_train, './data/mmseqs2_train_rd.fasta')\n",
    "write_fasta(df_valid, './data/mmseqs2_valid.fasta')\n",
    "write_fasta(df_test, './data/mmseqs2_test.fasta')\n",
    "\n",
    "print(len(df_train))\n",
    "print(len(df_test))\n",
    "print(len(df_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3882599b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_fasta_todict(fasta_file):\n",
    "\n",
    "    ids = []\n",
    "    seqs = []\n",
    "\n",
    "    with open(fasta_file, 'r') as fasta:\n",
    "            lines = fasta.read().split(\"\\n\")\n",
    "            for line in lines:\n",
    "                if line.startswith(\">\"):\n",
    "                    ids.append(line[1:])\n",
    "                else:\n",
    "                    if line != \"\":\n",
    "                        seqs.append(line)\n",
    "                        \n",
    "    return {\"BRMB_ID\":ids, \"Sequence\":seqs}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebaf132",
   "metadata": {},
   "source": [
    "# Easy_search filtering (mmseqs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f2a1e5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def red_reduce_es(df, easy_search_file):\n",
    "    \n",
    "    df_es = pd.read_csv(easy_search_file, sep=\"\\t\", header=None)\n",
    "\n",
    "    df1 = df_es[df_es[2]> 0.3]\n",
    "    \n",
    "    id_delete_1 = set(df1[1].values)\n",
    "    print(\"Entries above 0.3: \"+str(len(id_delete_1)))\n",
    "\n",
    "    \n",
    "    df = df.drop(df[df['BRMB_ID'].isin(id_delete_1)].index)\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ce42f366",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fasta_df(fastafile):\n",
    "    \n",
    "    dct = read_fasta_todict(fastafile)\n",
    "    df = pd.DataFrame.from_dict(dct)\n",
    "    df = df.astype({'BRMB_ID':'int'})\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7e1237b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def redundancy_reduce_fasta(fasta, m8_file, output):\n",
    "    \n",
    "    fasta_df = get_fasta_df(fasta)\n",
    "    #redundancy_reduce fasta\n",
    "    fasta_new = red_reduce_es(fasta_df,  m8_file)\n",
    "    write_fasta(fasta_new, output)\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7d1a6ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entries above 0.3: 68\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'redundancy_reduce_fasta(fasta=\"./data/graphpart/gp_train.fasta\", \\n                        m8_file=\"./data/easy_search/result_gp_test_train.m8\", \\n                        output=\\'./data/graphpart/gp_train_rd.fasta\\')'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "redundancy_reduce_fasta(fasta=\"./data/mmseqs2_train_rd.fasta\", \n",
    "                        m8_file=\"./data/train_test.m8\", \n",
    "                        output='./data/mmseqs2_train_rd.fasta')\n",
    "\n",
    "\n",
    "\"\"\"redundancy_reduce_fasta(fasta=\"./data/graphpart/gp_train.fasta\", \n",
    "                        m8_file=\"./data/easy_search/result_gp_test_train.m8\", \n",
    "                        output='./data/graphpart/gp_train_rd.fasta')\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b5f5ab70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 6408\n",
      "Validation: 250\n",
      "Test: 250\n"
     ]
    }
   ],
   "source": [
    "train = get_fasta_df(\"./data/mmseqs2_train_rd.fasta\")\n",
    "valid = get_fasta_df(\"./data/mmseqs2_valid.fasta\")\n",
    "test = get_fasta_df(\"./data/mmseqs2_test.fasta\")\n",
    "\n",
    "print(\"Train: \"+str(len(train)))\n",
    "print(\"Validation: \"+str(len(valid)))\n",
    "print(\"Test: \"+str(len(test)))\n",
    "\n",
    "#train_seq = train['Sequence'].values\n",
    "#seqs = [len(x) for x in train_seq]\n",
    "#plt.hist(seqs, bins=100)\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c14c99",
   "metadata": {},
   "source": [
    "# GraphPart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "id": "119c5b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_graphpart = pd.read_csv(graph_part, sep=\",\")\n",
    "\n",
    "\n",
    "train_gp = df_graphpart[df_graphpart['cluster'] == 1.0]\n",
    "test_gp = df_graphpart[df_graphpart['cluster'] == 0.0]\n",
    "valid_gp = df_graphpart[df_graphpart['cluster'] == 2.0]\n",
    "\n",
    "train_gp = filter_df(df_features, train_gp['AC'])\n",
    "test_gp = filter_df(df_features, test_gp['AC'])\n",
    "valid_gp = filter_df(df_features, valid_gp['AC'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "512e22a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 9972\n",
      "Validation: 49\n",
      "Test: 247\n"
     ]
    }
   ],
   "source": [
    "train_gp = get_fasta_df(\"./data/graphpart/gp_train_rd.fasta\")\n",
    "valid_gp = get_fasta_df(\"./data/graphpart/gp_valid.fasta\")\n",
    "test_gp = get_fasta_df(\"./data/graphpart/gp_test.fasta\")\n",
    "\n",
    "print(\"Train: \"+str(len(train_gp)))\n",
    "print(\"Validation: \"+str(len(valid_gp)))\n",
    "print(\"Test: \"+str(len(test_gp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "id": "cea88a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write_fasta(train_gp, './data/graphpart/gp_train.fasta')\n",
    "#write_fasta(valid_gp, './data/graphpart/gp_valid.fasta')\n",
    "#write_fasta(test_gp, './data/graphpart/gp_test.fasta')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab74457",
   "metadata": {},
   "source": [
    "# Easy_search Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "2f2ef0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_dict(peptide, start, end, dictionary):\n",
    "    \n",
    "    if peptide not in dictionary:\n",
    "        dictionary[peptide] = [[start,end]]\n",
    "    else:\n",
    "        pos_list = dictionary[peptide]\n",
    "        l = []\n",
    "        for pos in pos_list:\n",
    "            s = pos[0]\n",
    "            e = pos[1]\n",
    "            \n",
    "            if start < s and s < end:\n",
    "                if end < e:\n",
    "                    l.append([start,e])\n",
    "                else:\n",
    "                    l.append([start,end])\n",
    "                \n",
    "            elif s < start and start < e:\n",
    "                if e < end:\n",
    "                    l.append([s,end])\n",
    "                else: \n",
    "                    l.append([s,e])\n",
    "                \n",
    "            elif s == start and end == e:\n",
    "                l.append([s,e])\n",
    "                \n",
    "            else:\n",
    "                l.append([s,e])\n",
    "                l.append([start,end])\n",
    "                \n",
    "                \n",
    "        dictionary[peptide] = l\n",
    "        \n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e3c7f433",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_alignments(df, both):\n",
    "    \n",
    "    peptide_cov = {} #{peptide: [start, end]}\n",
    "\n",
    "    if both:\n",
    "        for index, row in df.iterrows():\n",
    "            q = row['query']\n",
    "            t = row['target']\n",
    "\n",
    "            peptide_cov = fill_dict(int(row['query']), int(row['qstart']), int(row['qend']), peptide_cov)\n",
    "            peptide_cov = fill_dict(int(row['target']), int(row['tstart']), int(row['tend']), peptide_cov)  \n",
    "    else:\n",
    "        for index, row in df.iterrows():\n",
    "            q = row['query']\n",
    "            peptide_cov = fill_dict(int(row['query']), int(row['qstart']), int(row['qend']), peptide_cov)\n",
    "            \n",
    "\n",
    "    return peptide_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "ff6d2633",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_coverage(alignment_dict, df_features):\n",
    "\n",
    "\n",
    "    # calculate peptide coverage\n",
    "    coverage_dict = {} #{peptide: coverage}\n",
    "    coverage_list = []\n",
    "\n",
    "    for entry, algn in alignment_dict.items():\n",
    "        seq = df_features[df_features[\"BRMB_ID\"]==entry][\"Sequence\"].values[0]\n",
    "        seq_len = len(seq)\n",
    "\n",
    "        algn_len = 0\n",
    "        for pos in algn:\n",
    "            algn_len = algn_len + (pos[1]-pos[0]+1)\n",
    "\n",
    "        #coverage\n",
    "        cov = algn_len/seq_len\n",
    "        coverage_dict[entry] = cov\n",
    "        coverage_list.append(cov)\n",
    "        #print(str(entry)+\": \"+str(seq_len)+\", \"+str(algn_len))\n",
    "\n",
    "    mean = sum(coverage_list) / len(coverage_list)\n",
    "    print(\"Mean of Coverage: \"+str(round(mean,2)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51328801",
   "metadata": {},
   "source": [
    "# Easy_search Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "29a21c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_dict_hn(pos_dict, peptide, position, peptide_dict_h, value_h, peptide_dict_n, value_n, ignore_existing_position):\n",
    "    \n",
    "    if peptide not in peptide_dict_h:\n",
    "        peptide_dict_h[peptide] = [[position, value_h]]\n",
    "        peptide_dict_n[peptide] = [[position, value_n]]\n",
    "        pos_dict[peptide] = [position]\n",
    "\n",
    "    else:\n",
    "        list_tmp_h = peptide_dict_h[peptide]\n",
    "        list_tmp_n = peptide_dict_n[peptide]\n",
    "        list_i = pos_dict[peptide]\n",
    "\n",
    "        #if position already exists in list, take the one with the highest difference\n",
    "        if position in list_i:\n",
    "            \n",
    "            #if ignore exisiting position: don't do anything\n",
    "            if not ignore_existing_position:\n",
    "            \n",
    "                index = list_i.index(position)\n",
    "                temp_h = list_tmp_h[index][1]\n",
    "                temp_n = list_tmp_n[index][1]\n",
    "\n",
    "                if temp_h < value_h:\n",
    "                    list_tmp_h[index] = [position, value_h]\n",
    "\n",
    "                if temp_n < value_n:\n",
    "                    list_tmp_n[index] = [position, value_n]\n",
    "\n",
    "        else:\n",
    "            list_tmp_h.append([position, value_h])\n",
    "            peptide_dict_h[peptide] = list_tmp_h\n",
    "            \n",
    "            list_tmp_n.append([position, value_n])\n",
    "            peptide_dict_n[peptide] = list_tmp_n\n",
    "\n",
    "            list_i.append(position)\n",
    "            pos_dict[peptide] =list_i\n",
    "            \n",
    "    return peptide_dict_h, peptide_dict_n, pos_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "114a581b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hn_per_protein(hn_file, alignments, df, seq_dict):\n",
    "    \n",
    "    df_hn = pd.read_csv(hn_file, sep=\"\\t\")\n",
    "    df_hn = df_hn.drop(df_hn[~df_hn['BRMB_ID'].isin(alignments.keys())].index)\n",
    "\n",
    "    #dict for query-protein values\n",
    "    peptide_h = {} #{peptide: [(position, h)]}\n",
    "    peptide_n = {} #{peptide: [(position, n)]}\n",
    "    \n",
    "    #dict for query-protein transferd annotation values\n",
    "    peptide_transfer_h = {} \n",
    "    peptide_transfer_n = {} \n",
    "    \n",
    "    \n",
    "    pep_pos1 = {} #{peptide: [position]}\n",
    "    pep_pos2 = {}\n",
    "\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        \n",
    "        q = row['query'] \n",
    "        q_pos = list(range(int(row['qstart']),int(row['qend'])+1))\n",
    "\n",
    "        t = row['target'] \n",
    "        t_pos = list(range(int(row['tstart']),int(row['tend'])+1))\n",
    "        \n",
    "        \n",
    "        df_q = df_hn[df_hn['BRMB_ID']== q]\n",
    "        df_t = df_hn[df_hn['BRMB_ID']== t]\n",
    "\n",
    "        df_q = df_q.drop(df_q[~df_q['AA_ID'].isin(q_pos)].index)\n",
    "        df_t = df_t.drop(df_t[~df_t['AA_ID'].isin(t_pos)].index)  \n",
    "\n",
    "\n",
    "        # go though aligment: M (match), D (deletion, gap in query), or I (Insertion, gap in target)\n",
    "        alignment = re.split(\"(M|D|I)\",row['cigar'])[:-1] \n",
    "\n",
    "\n",
    "        current_pos_q = q_pos[0]\n",
    "        current_pos_t = t_pos[0]\n",
    "\n",
    "\n",
    "        #iterate over local aligment\n",
    "        for i in range(0, len(alignment), 2):\n",
    "\n",
    "            action = alignment[i+1]\n",
    "            step = int(alignment[i])\n",
    "\n",
    "            positions_q =list(range(current_pos_q, current_pos_q+step))\n",
    "            positions_t =list(range(current_pos_t, current_pos_t+step))\n",
    "\n",
    "            if action == 'M':\n",
    "                df_q_cur = df_q.drop(df_q[~df_q['AA_ID'].isin(positions_q)].index)\n",
    "                df_t_cur = df_t.drop(df_t[~df_t['AA_ID'].isin(positions_t)].index)\n",
    "\n",
    "                q_l = df_q_cur['AA_ID'].values\n",
    "                t_l = df_t_cur['AA_ID'].values\n",
    "\n",
    "                    \n",
    "\n",
    "                #check if H/N entries for all the positions are annotated\n",
    "                #extract H/N values for existing ones\n",
    "                for i in range(0, step):\n",
    "                    i_q = positions_q[i]\n",
    "                    i_t = positions_t[i]\n",
    "\n",
    "\n",
    "                    \n",
    "                    if i_q in q_l and i_t in t_l:\n",
    "                        h_q = df_q_cur[df_q_cur['AA_ID'] == i_q]['H'].values[0]\n",
    "                        n_q = df_q_cur[df_q_cur['AA_ID'] == i_q]['N'].values[0]\n",
    "\n",
    "                        h_t = df_t_cur[df_t_cur['AA_ID'] == i_t]['H'].values[0]\n",
    "                        n_t = df_t_cur[df_t_cur['AA_ID'] == i_t]['N'].values[0]\n",
    "                        \n",
    "                        #h_diff = abs(h_q - h_t)\n",
    "                        #n_diff = abs(n_q - n_t)\n",
    "                            \n",
    "                        #fill dictionary with peptide: position, h-difference\n",
    "                        peptide_transfer_h, peptide_transfer_n, pep_pos1 = fill_dict_hn(pep_pos1, q, i_q, peptide_transfer_h, h_t,\n",
    "                                                                               peptide_transfer_n, n_t, ignore_existing_position=True)\n",
    "                        \n",
    "                        peptide_h, peptide_n, pep_pos2 = fill_dict_hn(pep_pos2, q, i_q, peptide_h, h_q,\n",
    "                                                                               peptide_n, n_q, ignore_existing_position=True)\n",
    "\n",
    "\n",
    "                current_pos_t = current_pos_t+step\n",
    "                current_pos_q = current_pos_q+step\n",
    "\n",
    "\n",
    "            elif action == 'D':\n",
    "                current_pos_t = current_pos_t+step\n",
    "\n",
    "            elif action == 'I':\n",
    "                current_pos_q = current_pos_q+step\n",
    "        \n",
    "        \n",
    "    return  peptide_transfer_h, peptide_h, peptide_transfer_n, peptide_n  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "4260046a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#go through dictionary with biggest H/N differences and \n",
    "#put if H_difference<=0.04 and N_difference<=0.2 == 1 else 0 \n",
    "#take sum and divide by sequence length\n",
    "#per protein\n",
    "\n",
    "def get_accuracy_per_protein(dct, threshold, df_length):\n",
    "    n = threshold\n",
    "    experimental_error_proteins = {} #{protein: binary_list of difference of H/N within experimental_error}\n",
    "\n",
    "    for k,value in dct.items():\n",
    "        binary_list = [1 if v[1] <= n else 0 for v in value]\n",
    "\n",
    "        seq = df_length[df_length[\"BRMB_ID\"]==k][\"Sequence\"].values[0]\n",
    "        seq_len = len(seq)\n",
    "\n",
    "        experimental_error_proteins[k] = sum(binary_list)/seq_len\n",
    "\n",
    "    return experimental_error_proteins\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "9e0d4d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accucary_mean(dct):\n",
    "    v =  dct.values()\n",
    "    return sum(v)/len(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7faf5ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mse_mean(dict_true, dict_transfered):\n",
    "    mses = []\n",
    "    for protein in dict_true:\n",
    "        true = [tup[1] for tup in dict_true[protein]]\n",
    "        pred = [tup[1] for tup in dict_transfered[protein]]\n",
    "        mse = mean_squared_error(true, pred)\n",
    "        mses.append(mse)\n",
    "        \n",
    "    return sum(mses)/len(mses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060f682d",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1f0368b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coverage_accuracy(file, features, hn):\n",
    "    #--format-output query,target,fident,alnlen,mismatch,gapopen,qstart,qend,tstart,tend,evalue,bits\n",
    "\n",
    "    easy_search_file = file\n",
    "    print(re.split(\"/\",easy_search_file)[-1])\n",
    "\n",
    "    m8 = pd.read_csv(easy_search_file, sep=\"\\t\", header=None, \n",
    "                         names=[\"query\",\"target\",\"fident\",\"alnlen\",\"mismatch\",\"gapopen\",\"qstart\",\"qend\",\"tstart\",\"tend\",\"evalue\",\"bits\",\"cigar\"])\n",
    "\n",
    "    \n",
    "    #filter out rows with alignment > 0.3\n",
    "    m8 = m8.drop(m8[m8['fident']> 0.3].index)\n",
    "    #m8 = m8.sort_values(by = 'evalue')\n",
    "    print(m8)\n",
    "    \n",
    "    \n",
    "    df_features = pd.read_csv(features, sep=\"\\t\")\n",
    "    \n",
    "    \n",
    "    alignments_all = get_alignments(m8, both=True)\n",
    "    alignments_q = get_alignments(m8, both=False)\n",
    "\n",
    "    calculate_coverage(alignments_q, df_features)\n",
    "\n",
    "\n",
    "    ####Accuracy\n",
    "    diffs_h, diffs_n = get_hn_differences_per_protein(hn, alignments_all, m8)\n",
    "\n",
    "    accuracy_h = get_accuracy_per_protein(diffs_h, 0.04, df_features)\n",
    "    accuracy_n = get_accuracy_per_protein(diffs_n, 0.2, df_features)\n",
    "\n",
    "    mean_h = accucary_mean(accuracy_h)\n",
    "    mean_n = accucary_mean(accuracy_n)\n",
    "\n",
    "    print(\"Accuracy H: \"+str(round(mean_h,2)))\n",
    "    print(\"Accuracy N: \"+str(round(mean_n,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "8dc01847",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coverage_mse(file, features, hn):\n",
    "    #--format-output query,target,fident,alnlen,mismatch,gapopen,qstart,qend,tstart,tend,evalue,bits\n",
    "\n",
    "    easy_search_file = file\n",
    "    print(re.split(\"/\",easy_search_file)[-1])\n",
    "\n",
    "    m8 = pd.read_csv(easy_search_file, sep=\"\\t\", header=None, \n",
    "                         names=[\"query\",\"target\",\"fident\",\"alnlen\",\"mismatch\",\"gapopen\",\"qstart\",\"qend\",\"tstart\",\"tend\",\"evalue\",\"bits\",\"cigar\"])\n",
    "\n",
    "    \n",
    "    #filter out rows with alignment > 0.3\n",
    "    m8 = m8.drop(m8[m8['fident']> 0.3].index)\n",
    "    #print(m8)\n",
    "\n",
    "    alignments_all = get_alignments(m8, both=True)\n",
    "    alignments_q = get_alignments(m8, both=False)\n",
    "    \n",
    "    df_features = pd.read_csv(features, sep=\"\\t\")\n",
    "    \n",
    "    #dictionary of query-protein:sequence\n",
    "    df_seq = df_features[df_features[\"BRMB_ID\"].isin(m8['query'])]\n",
    "    seq_dict = dict([(i,x) for i,x in zip(df_seq['BRMB_ID'], df_seq['Sequence'])])\n",
    "\n",
    "\n",
    "    peptide_transfer_h, peptide_h, peptide_transfer_n, peptide_n  = get_hn_per_protein(hn, alignments_all, m8, seq_dict)\n",
    "    \n",
    "    #### MSE\n",
    "    mse_h = get_mse_mean(peptide_h, peptide_transfer_h)\n",
    "    mse_n = get_mse_mean(peptide_n, peptide_transfer_n)\n",
    "   \n",
    "    print(\"MSE H: \"+str(round(mse_h,2)))\n",
    "    print(\"MSE N: \"+str(round(mse_n,2)))\n",
    "    \n",
    "    #### Coverage\n",
    "    cov_list = []\n",
    "    for protein in peptide_transfer_h:\n",
    "        l = len(peptide_transfer_h[protein])\n",
    "        cov = l/len(seq_dict[protein])\n",
    "        #print(protein)\n",
    "        #print(\"residues: \"+str(l)+\" of \"+str(len(seq_dict[protein])))\n",
    "        cov_list.append(cov)\n",
    "   \n",
    "\n",
    "    coverage = sum(cov_list)/len(cov_list)\n",
    "    print(\"Coverage: \"+str(round(coverage,2)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605f21dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result_mmseq_valid_train.m8\n",
      "MSE H: 0.62\n",
      "MSE N: 36.08\n",
      "Coverage: 0.65\n",
      "\n",
      "\n",
      "result_mmseq_test_train.m8\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "for subdir, dirs, files in os.walk(\"./data/mmseqs2/\"):\n",
    "    for file in files:\n",
    "        if file.endswith(\".m8\"):\n",
    "            f = os.path.join(subdir, file)\n",
    "            \n",
    "            get_coverage_mse(f,feature_file, output_hn)\n",
    "            print(\"\\n\")\n",
    "\n",
    "\n",
    "#get_coverage_accuracy(\"./data/easy_search/result_gp_train_valid2.m8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "e87d04b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entries above 0.3: 5\n"
     ]
    }
   ],
   "source": [
    "#redundancy_reduce_fasta(\"./data/mmseqs2/mmseqs2_valid_rd.fasta\", \"./data/easy_search/result_mmseq_train_valid_rd.m8\", \"./data/mmseqs2/mmseqs2_valid_rd.fasta\")\n",
    "\n",
    "#Aber man will ja eine möglichst niedrige Coverage \n",
    "#und einen möglichst hohen/schlechten MSE bei unserem aktuellen Experiment\n",
    "#Die Idee ist ja zu schauen inwiefern HBI (homology-based inference) selbst nach redundancy reduction \n",
    "#noch funktioniert. Wenn die redundancy reduction perfekt funktioniert hätte, \n",
    "#sollte man ja eine coverage von 0 erhalten (absolut keine Hits mehr) und einen MSE der Random entspricht."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NMR_master",
   "language": "python",
   "name": "nmr_master"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
